{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ceeeb46",
   "metadata": {},
   "source": [
    "# Discussion 5\n",
    "## This is just a demonstration how to solve the homework using the iris.csv that we previously used in Discussion 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264c751",
   "metadata": {},
   "source": [
    "## Exercise 1 : Building a Feed-Forward Neural Network(50 points)\n",
    "\n",
    "<img src=\"./ffnn.JPG\"/>\n",
    "Multiple input attributes go through a hidden layer to the output. When training the model, the hidden layer is trained so that the produced output get as close to the actual output as possible\n",
    "\n",
    "### Exercise 1.1 : Data Preprocessing (10 points)\n",
    "\n",
    "- As the classes are categorical, use one-hot encoding to represent the set of classes. You will find this useful when developing the output layer of the neural network.\n",
    "- Normalize each field of the input data using the min-max normalization technique.\n",
    "\n",
    "### Exercise 1.2 : Training and Testing the Neural Network (40 points)\n",
    "\n",
    "Design a 4-layer artificial neural network, specifically a feed-forward multi-layer perceptron (using the sigmoid activation function), to classify the type of 'Dry Bean' given the other attributes in the data set, similar to the one mentioned in the paper above. Please note that this is a multi-class classification problem so select the right number of nodes accordingly for the output layer.\n",
    "\n",
    "For training and testing the model, split the data into training and testing set by __80:20__ and use the training set for training the model and the test set to evaluate the model performance.\n",
    "\n",
    "Consider the following hyperparameters while developing your model :\n",
    "\n",
    "- Number of nodes in each hidden layer should be (10, 2)\n",
    "- Learning rate should be 0.4\n",
    "- Number of epochs should be 600\n",
    "- The sigmoid function should be used as the activation function in each layer\n",
    "- Stochastic Gradient Descent should be used to minimize the error rate\n",
    "\n",
    "__Requirements once the model has been trained :__\n",
    "\n",
    "- A confusion matrix for all classes, specifying the true positive, true negative, false positive, and false negative cases for each category in the class\n",
    "- The accuracy and mean squared error (MSE) of the model\n",
    "- The precision and recall for each label in the class\n",
    "\n",
    "__Notes :__\n",
    "\n",
    "- Splitting of the dataset should be done __after__ the data preprocessing step.\n",
    "- The mean squared error (MSE) values obtained __should be positive__.\n",
    "\n",
    "<!-- ## Part 1 (50 points)\n",
    "\n",
    "Design a 4-layer artificial neural network, specifically a feed-forward multi-layer perceptron (using the sigmoid activation function), to classify the type of 'Dry Bean' given the other attributes in the data set, similar to the one mentioned in the paper above. For this, split the data into training and testing set by 90:10 and use the training set for training the model and the test set to evaluate the model performance. Please note that this is a multi-class classification problem so select the right number of nodes accordingly for the output layer.\n",
    "\n",
    "Consider the following hyperparameters :\n",
    "\n",
    "- Number of nodes in each hidden layer should be (12, 3).\n",
    "- Learning rate should be 0.3\n",
    "- Number of epochs should be 500\n",
    "- The sigmoid function should be used as the activation function in each layer\n",
    "- Stochastic Gradient Descent should be used to minimize the error rate\n",
    "\n",
    "Once the model has been trained, test the model and obtain the following :\n",
    "\n",
    "- The confusion matrix for each class, specifying the true positive, true negative, false positive, and false negative cases for each category in the class\n",
    "- The accuracy and mean squared error (MSE) of the model\n",
    "- The precision and recall for each label in the class\n",
    "\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aaef083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0edfcba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "Species : \n",
      "['setosa' 'versicolor' 'virginica']\n",
      "Dimensions of the dataset :  (150, 5)\n",
      "Features of the dataset :\n",
      "        sepal_length  sepal_width  petal_length  petal_width species\n",
      "count     150.000000   150.000000    150.000000   150.000000     150\n",
      "unique           NaN          NaN           NaN          NaN       3\n",
      "top              NaN          NaN           NaN          NaN  setosa\n",
      "freq             NaN          NaN           NaN          NaN      50\n",
      "mean        5.843333     3.054000      3.758667     1.198667     NaN\n",
      "std         0.828066     0.433594      1.764420     0.763161     NaN\n",
      "min         4.300000     2.000000      1.000000     0.100000     NaN\n",
      "25%         5.100000     2.800000      1.600000     0.300000     NaN\n",
      "50%         5.800000     3.000000      4.350000     1.300000     NaN\n",
      "75%         6.400000     3.300000      5.100000     1.800000     NaN\n",
      "max         7.900000     4.400000      6.900000     2.500000     NaN\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "print(\"Dataset :\")\n",
    "print(dataset.head())\n",
    "print(\"Species : \")\n",
    "print(dataset['species'].unique())\n",
    "\n",
    "print(\"Dimensions of the dataset : \", dataset.shape)\n",
    "print(\"Features of the dataset :\")\n",
    "print(dataset.describe(include = 'all'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca9f848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         setosa\n",
       "1         setosa\n",
       "2         setosa\n",
       "3         setosa\n",
       "4         setosa\n",
       "         ...    \n",
       "145    virginica\n",
       "146    virginica\n",
       "147    virginica\n",
       "148    virginica\n",
       "149    virginica\n",
       "Name: species, Length: 150, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44211bcb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed data :\n",
      "     sepal_length  sepal_width  petal_length  petal_width\n",
      "0        0.222222     0.625000      0.067797     0.041667\n",
      "1        0.166667     0.416667      0.067797     0.041667\n",
      "2        0.111111     0.500000      0.050847     0.041667\n",
      "3        0.083333     0.458333      0.084746     0.041667\n",
      "4        0.194444     0.666667      0.067797     0.041667\n",
      "..            ...          ...           ...          ...\n",
      "145      0.666667     0.416667      0.711864     0.916667\n",
      "146      0.555556     0.208333      0.677966     0.750000\n",
      "147      0.611111     0.416667      0.711864     0.791667\n",
      "148      0.527778     0.583333      0.745763     0.916667\n",
      "149      0.444444     0.416667      0.694915     0.708333\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "Pre-processed class :\n",
      "     setosa  versicolor  virginica\n",
      "0         1           0          0\n",
      "1         1           0          0\n",
      "2         1           0          0\n",
      "3         1           0          0\n",
      "4         1           0          0\n",
      "..      ...         ...        ...\n",
      "145       0           0          1\n",
      "146       0           0          1\n",
      "147       0           0          1\n",
      "148       0           0          1\n",
      "149       0           0          1\n",
      "\n",
      "[150 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, batch_size=100, hidden_layer_sizes=(10, 2),\n",
       "              learning_rate_init=0.4, max_iter=600, random_state=42,\n",
       "              solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, batch_size=100, hidden_layer_sizes=(10, 2),\n",
       "              learning_rate_init=0.4, max_iter=600, random_state=42,\n",
       "              solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', batch_size=100, hidden_layer_sizes=(10, 2),\n",
       "              learning_rate_init=0.4, max_iter=600, random_state=42,\n",
       "              solver='sgd')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = dataset.drop('species', axis = 1)\n",
    "y = dataset['species']\n",
    "\n",
    "# normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_rescaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(data = X_rescaled, columns = X.columns)\n",
    "\n",
    "set_of_classes = y.value_counts().index.tolist()\n",
    "set_of_classes= pd.DataFrame({'species': set_of_classes})\n",
    "y = pd.get_dummies(y)\n",
    "\n",
    "print(\"Pre-processed data :\")\n",
    "print(X)\n",
    "\n",
    "print(\"Pre-processed class :\")\n",
    "print(y)\n",
    "\n",
    "#splitting data into ratio 80:20\n",
    "data_train, data_test, class_train, class_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Number of nodes in each hidden layer should be (10, 2)\n",
    "# Learning rate should be 0.4\n",
    "# Number of epochs should be 600\n",
    "mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.4, batch_size = 100, hidden_layer_sizes = (10, 2), max_iter = 600)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d9dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['species']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ccaf5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(data_train, class_train)\n",
    "\n",
    "pred = mlp.predict(data_test)\n",
    "pred\n",
    "#prediction on the test data. species are represented using the hot-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8d7802",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9333333333333333\n",
      "Mean Square Error :  0.044444444444444446\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n",
      "Confusion Matrix for each label : \n",
      "[[[21  0]\n",
      "  [ 0  9]]\n",
      "\n",
      " [[15  0]\n",
      "  [ 2 13]]\n",
      "\n",
      " [[22  2]\n",
      "  [ 0  6]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.87      0.93        15\n",
      "           2       0.75      1.00      0.86         6\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        30\n",
      "   macro avg       0.92      0.96      0.93        30\n",
      "weighted avg       0.95      0.93      0.94        30\n",
      " samples avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(class_test, pred))\n",
    "print(\"Mean Square Error : \", mean_squared_error(class_test, pred))\n",
    "\n",
    "print(pred[:5])\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "print(multilabel_confusion_matrix(class_test, pred))\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(class_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba0fb7",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "<img src=\"./matrix.png\" style=\"width:200px;height:200px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f5188",
   "metadata": {},
   "source": [
    "## Exercise 2 : k-fold Cross Validation (10 points)\n",
    "\n",
    "In order to avoid using biased models, use 8-fold cross validation to generalize the model based on the given data set.\n",
    "\n",
    "__Requirements :__\n",
    "- The accuracy and MSE values during each iteration of the cross validation\n",
    "- The overall average accuracy and MSE value\n",
    "\n",
    "__Note :__ The mean squared error (MSE) values obtained should be positive.\n",
    "\n",
    "<img src=\"./k_fold.jpg\" style=\"width:300px;height:400px\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5adc7081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "[1.         1.         1.         0.84210526 0.94736842 1.\n",
      " 1.         0.83333333]\n",
      "MSE\n",
      "[0.         0.         0.         0.10526316 0.03508772 0.\n",
      " 0.         0.11111111]\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn function cross_validate()\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "CV = cross_validate(mlp, X, y, cv=8, scoring=['accuracy', 'neg_mean_squared_error'])\n",
    "print('Accuracy')\n",
    "print(CV['test_accuracy'])\n",
    "print('MSE')\n",
    "print(-1*CV['test_neg_mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5b043aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy =  0.9528508771929824\n",
      "Average MSE =  0.031432748538011694\n"
     ]
    }
   ],
   "source": [
    "print('Average Accuracy = ', sum(CV['test_accuracy']) / len(CV['test_accuracy']))\n",
    "print('Average MSE = ', sum(-1 * CV['test_neg_mean_squared_error']) / len(CV['test_neg_mean_squared_error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da67faa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for batch  1  :  1.0\n",
      "Mean Square Error for batch  1  :  0.0\n",
      "\n",
      "Accuracy for batch  2  :  1.0\n",
      "Mean Square Error for batch  2  :  0.0\n",
      "\n",
      "Accuracy for batch  3  :  1.0\n",
      "Mean Square Error for batch  3  :  0.0\n",
      "\n",
      "Accuracy for batch  4  :  1.0\n",
      "Mean Square Error for batch  4  :  0.0\n",
      "\n",
      "Accuracy for batch  5  :  0.9473684210526315\n",
      "Mean Square Error for batch  5  :  0.03508771929824561\n",
      "\n",
      "Accuracy for batch  6  :  1.0\n",
      "Mean Square Error for batch  6  :  0.0\n",
      "\n",
      "Accuracy for batch  7  :  1.0\n",
      "Mean Square Error for batch  7  :  0.0\n",
      "\n",
      "Accuracy for batch  8  :  0.8333333333333334\n",
      "Mean Square Error for batch  8  :  0.1111111111111111\n",
      "\n",
      "Average Accuracy =  0.9725877192982456\n",
      "Average MSE =  0.01827485380116959\n"
     ]
    }
   ],
   "source": [
    "# To find list of accuracy and MSE values\n",
    "# Without using the sklearn function cross_validate()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_splits=8\n",
    "# step 1: randomize the dataset and create k equal size partitions\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "acc = 0\n",
    "mse = 0\n",
    "\n",
    "i = 0 #keep track of batch number\n",
    "# step 5: iterate k times with a different testing subset\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # step 2-3: use k-1/k^th partition for the training/testing model\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\n",
    "    \n",
    "    # perform the training similar to Q1\n",
    "    #this was based on the requirements in Q1\n",
    "    mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.4, batch_size = 100, hidden_layer_sizes = (10, 2), max_iter = 600)\n",
    "    mlp.fit(X[start_train:stop_train], y[start_train:stop_train])\n",
    "    pred = mlp.predict(X[start_test:stop_test])\n",
    "    \n",
    "    # step 4: record the evaluating scores\n",
    "    i+=1\n",
    "    acc += accuracy_score(y[start_test:stop_test], pred)\n",
    "    mse += mean_squared_error(y[start_test:stop_test], pred)\n",
    "    \n",
    "    print(\"\\nAccuracy for batch \", i, \" : \", accuracy_score(y[start_test:stop_test], pred))\n",
    "    print(\"Mean Square Error for batch \", i, \" : \", mean_squared_error(y[start_test:stop_test], pred))\n",
    "\n",
    "# step 6: find the average and select the batch with highest evaluation scores\n",
    "print('\\nAverage Accuracy = ', acc / n_splits)\n",
    "print('Average MSE = ', mse / n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff8210e",
   "metadata": {},
   "source": [
    "## Exercise 3 - Logistic Regression (20 points in total)\n",
    "Recall the dataset from last week homework (Discussion use iris.csv)\n",
    "\n",
    "Now we are going to build a classification model on ``species`` using all the other 4 attributes. <br >\n",
    "Note that Logistic Regression is a binary classificaiton algorithm.\n",
    "\n",
    "### Exercise 3.1 - Processing and Splitting the Dataset (5 points)\n",
    "In this exercise 3, we only consider those species of \"versicolor\" or \"virginica\". <br >\n",
    "So please **remove** those species that belong to \"setosa\". <br >\n",
    "And then, split the data into training and testing set with the ratio of 70:30. <br >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5428dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./iris - Copy.csv')\n",
    "\n",
    "data = df.copy().loc[(df['species'] != 'setosa'), :]\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=21)\n",
    "# The remaining\n",
    "X_train, y_train = train.drop(columns=['species']) ,train['species']\n",
    "X_test, y_test = test.drop(columns=['species']), test['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03599c45",
   "metadata": {},
   "source": [
    "### Exercise 3.2 - Logistic Regression (15 points)\n",
    "\n",
    "Using all the other 4 attributes, please build a Logistic Regression model that distinguishes between flowers in versicolor versus virginica. <br >\n",
    "\n",
    "Requirements\n",
    " - Report the testing precision and recall for both species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e8b51f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  versicolor       1.00      0.90      0.95        21\n",
      "   virginica       0.82      1.00      0.90         9\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.91      0.95      0.93        30\n",
      "weighted avg       0.95      0.93      0.94        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cls = LogisticRegression()\n",
    "cls.fit(X_train, y_train)\n",
    "print(classification_report(y_test, cls.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892911b",
   "metadata": {},
   "source": [
    "**precision**: proportion of TP to the total number of positive predictions (TP+FP) <br>\n",
    "**recall**: true positive rate, which is the proportion of true positive (TP) \n",
    "predictions to the total number of actual positive instances (TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d849f",
   "metadata": {},
   "source": [
    "## Exercise 4 - Polynomial Regression (20 points in total)\n",
    "Check out the notebook file that Professor went over in class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
