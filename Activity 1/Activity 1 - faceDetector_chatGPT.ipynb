{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT Face Detector\n",
    "Below are two programs about face recognition obtained from ChatGPT using various techniques of machine learning. \n",
    "\n",
    "### Background Context\n",
    "##### K-Nearest Neighbors (KNN)\n",
    "A popular supervised machine learning algorithm used in regression and classification. The model prediction is based on the similarities between the unseen data from the test set and its k nearest neighbors in the training set.<br>\n",
    "- **Advantage:** simple and easy to implement <br>\n",
    "- **Disadvantage:** lazy learner (train while making prediction) so slower and more costly (memory)\n",
    "\n",
    "##### Convolutional Neural Network (CNN)\n",
    "A type of deep learning neural network architecture used for image and speech processing. By using multiple interconnected layers, they can extract useful features from the input data and use them to make predictions<br>\n",
    "- **Advantage:** multiple layers enable capture and recognize variations of data<br>\n",
    "- **Disadvantage:** high complexity (expensive to train and use)<br>\n",
    "\n",
    "### About the Dataset\n",
    "The file contains two set of data: training and testing in the `train` and `val` folders respectively. Each of them contains two set of randomly chosen images displaying two different type of facial expressions: happy and sad. \n",
    "\n",
    "Data size: \n",
    "|  | train | test |\n",
    "| --- | --- | --- |\n",
    "| happy men | 25 | 5 |\n",
    "| happy women | 25 | 5 |\n",
    "| sad men | 25 | 5 |\n",
    "| sad women | 25 | 5 |\n",
    "\n",
    "[Image Source](https://stock.adobe.com/)\n",
    "\n",
    "### Your tasks: \n",
    "KNN Model:\n",
    "- Explain what does `Accuracy` tells you.\n",
    "- Compute `precision` and `recall` and explain what they mean.\n",
    "<br>\n",
    "\n",
    "CNN Model:\n",
    "- Train the model with the given dataset. What could do potentially improves `accuracy` of the model?\n",
    "- Explain what does `loss` and `accuracy` tells you.\n",
    "- Compute TP, TN, FP, FN\n",
    "- Compute Precision and Recall\n",
    "- How much of the True Positive were Male? Female?\n",
    "- How much of the True Negative were Male? Female?\n",
    "- Create a bar chart to show these proportion in terms of percentage.\n",
    "\n",
    "### Format:\n",
    "- For questions that require justification, include all your answers in a (one) Markdown cell after each program.\n",
    "- For questions that require programming output, make sure it's clear what each output is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6085271317829457\n",
      "Precision: 0.5951639802465996\n",
      "Recall: 0.6085271317829457\n"
     ]
    }
   ],
   "source": [
    "#use KNN\n",
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Load the LFW dataset\n",
    "# downloads and returns the images of people's face and labels\n",
    "# only include people with at least 70 images in the dataset\n",
    "lfw = datasets.fetch_lfw_people(min_faces_per_person=70)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(lfw.data, lfw.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a K-Nearest Neighbors classifier\n",
    "# n_neighbors: use the 5 nearest neighbors to make the predictions\n",
    "knn = KNeighborsClassifier(n_neighbors=12)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "# comparing the predicted labels (y_pred) with the true labels (y_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the accuracy of the classifier\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# accuracy gives the proportion of accurately predicted sample from the total number of sample\n",
    "# the closer to 1 the better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy tells us the ratio (unnormalized) of correctly predicted labels within the fed dataset. More specifically, after asking the model to predict on 'X_test,' it produces its dataframe of predictions into y_pred. The ratio of differences between y_pred and y_test dataframe (which is the frame that contains the properly labeled 'answers' or 'outputs') is then calculated by counting the differences between the two. In short, accuracy tells us the percentage of correct labels it got on the predicted test set.\n",
    "\n",
    "The formula for Precision is as such: tp/(tp+fp) where tp and fp are true positives and false positives respectively. The precision tells us the ratio of correctly labeled positives to the total ratio of positives. Essentially, it judges the ability of the model to correctly identify a positive label. For example, precision can tell us the ratio between the correct amount of happy faces it detected versus the total amount of happy faces it detected. \n",
    "\n",
    "The formula for Recall is as such: tp/(tp+fn) where tp and fn are true positives and false negatives respectively. Recall tells us the amount of positives the model predicted correctly out of all positives that exist within the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 4s 72ms/step - loss: 0.6970 - accuracy: 0.4742 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 5s 162ms/step - loss: 0.7005 - accuracy: 0.4433 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 5s 158ms/step - loss: 0.6960 - accuracy: 0.4639 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 5s 147ms/step - loss: 0.6968 - accuracy: 0.5155 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 0.6938 - accuracy: 0.5670 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 0.6908 - accuracy: 0.5361 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6981 - accuracy: 0.4845 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6960 - accuracy: 0.5052 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.6998 - accuracy: 0.4639 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 3s 104ms/step - loss: 0.6967 - accuracy: 0.4845 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 3s 100ms/step - loss: 0.6961 - accuracy: 0.4948 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6951 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.4444\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.6969 - accuracy: 0.4639 - val_loss: 0.6930 - val_accuracy: 0.4444\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 3s 97ms/step - loss: 0.6948 - accuracy: 0.5052 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 3s 97ms/step - loss: 0.6964 - accuracy: 0.4330 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.6968 - accuracy: 0.4639 - val_loss: 0.6929 - val_accuracy: 0.4444\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 3s 93ms/step - loss: 0.6950 - accuracy: 0.4948 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.6951 - accuracy: 0.5155 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.6978 - accuracy: 0.4845 - val_loss: 0.6928 - val_accuracy: 0.5556\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.6959 - accuracy: 0.4948 - val_loss: 0.6928 - val_accuracy: 0.5556\n",
      "34/34 [==============================] - 1s 21ms/step\n",
      "7/7 [==============================] - 0s 19ms/step\n",
      "\n",
      " Training Values:\n",
      "True Positive (TP): 32\n",
      "True Negative (TN): 20\n",
      "False Positive (FP): 30\n",
      "False Negative (FN): 18\n",
      "\n",
      " Validation Values:\n",
      "True Positive (TP): 5\n",
      "True Negative (TN): 6\n",
      "False Positive (FP): 4\n",
      "False Negative (FN): 5\n"
     ]
    }
   ],
   "source": [
    "#use CNN\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the directory paths for the training and validation datasets\n",
    "train_dir = 'train'\n",
    "val_dir = 'val'\n",
    "\n",
    "# Define the number of classes (male and female)\n",
    "num_classes = 2\n",
    "\n",
    "# Define the input shape of the images\n",
    "input_shape = (160, 160, 1)\n",
    "\n",
    "# Define the batch size for the data generators\n",
    "batch_size = 3\n",
    "\n",
    "# Define the data generators for the training and validation datasets\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples//batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples//batch_size\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('face_classification_model.h5')\n",
    "\n",
    "y_pred_train = model.predict(train_generator) #train_generator\n",
    "y_true_train = train_generator.classes\n",
    "\n",
    "y_pred_val = model.predict(val_generator)\n",
    "y_true_val = val_generator.classes\n",
    "\n",
    "y_pred_binary_train = np.argmax(y_pred_train, axis=1)\n",
    "y_pred_binary_val = np.argmax(y_pred_val, axis=1)\n",
    "\n",
    "cm_train = confusion_matrix(y_true_train, y_pred_binary_train)\n",
    "cm_val = confusion_matrix(y_true_val, y_pred_binary_val)\n",
    "\n",
    "TP = cm_train[1, 1]\n",
    "TN = cm_train[0, 0]\n",
    "FP = cm_train[0, 1]\n",
    "FN = cm_train[1, 0]\n",
    "\n",
    "print(\"\\n Training Values:\")\n",
    "print(\"True Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "\n",
    "TP = cm_val[1, 1]\n",
    "TN = cm_val[0, 0]\n",
    "FP = cm_val[0, 1]\n",
    "FN = cm_val[1, 0]\n",
    "\n",
    "print(\"\\n Validation Values:\")\n",
    "print(\"True Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Train: 0.5212224108658744\n",
      "Recall Train: 0.52\n",
      "Precision Val: 0.5505050505050505\n",
      "Recall Val: 0.55\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true_train, y_pred_binary_train, average='weighted')\n",
    "recall = recall_score(y_true_train, y_pred_binary_train, average='weighted')\n",
    "print(\"Precision Train:\", precision)\n",
    "print(\"Recall Train:\", recall)\n",
    "precision = precision_score(y_true_val, y_pred_binary_val, average='weighted')\n",
    "recall = recall_score(y_true_val, y_pred_binary_val, average='weighted')\n",
    "print(\"Precision Val:\", precision)\n",
    "print(\"Recall Val:\", recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_binary_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f\\\\happy53.jpg',\n",
       " 'f\\\\happy55.jpg',\n",
       " 'f\\\\happy56.jpg',\n",
       " 'f\\\\happy57.jpg',\n",
       " 'f\\\\happy60.jpg',\n",
       " 'f\\\\sad51.jpg',\n",
       " 'f\\\\sad52.jpg',\n",
       " 'f\\\\sad54.jpg',\n",
       " 'f\\\\sad55.jpg',\n",
       " 'f\\\\sad60.jpg',\n",
       " 'm\\\\happy51.jpg',\n",
       " 'm\\\\happy52.jpg',\n",
       " 'm\\\\happy54.jpg',\n",
       " 'm\\\\happy58.jpg',\n",
       " 'm\\\\happy59.jpg',\n",
       " 'm\\\\sad53.jpg',\n",
       " 'm\\\\sad56.jpg',\n",
       " 'm\\\\sad57.jpg',\n",
       " 'm\\\\sad58.jpg',\n",
       " 'm\\\\sad59.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_generator.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 0 , f\\happy56.jpg\n",
      "This shows that the True Negatives are female. In other words, 0 represents female in this data.\n",
      "1 , 1 , m\\sad58.jpg\n",
      "This shows that the True Positives are male. In other words, 1 represents male in this data.\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_binary_val[2], \",\",y_true_val[2],\",\",val_generator.filenames[2])\n",
    "print(\"This shows that the True Negatives are female. In other words, 0 represents female in this data.\")\n",
    "print(y_pred_binary_val[-2], \",\",y_true_val[-2],\",\",val_generator.filenames[-2])\n",
    "print(\"This shows that the True Positives are male. In other words, 1 represents male in this data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the accuracy of the model, we can adjust the various hyperparameters such as batch_size and epochs. Since our dataset is very small, I lowered the batch_size from 5 to 3. I also increased the number of parameters within the model by adding more Convolution layers as well as adding in Dropout layers to decrease overfitting. I then made the learning rate 1e-6 from 1e-3 and increased the number of epochs so we can extract more detailed features. \n",
    "\n",
    "Our loss function is cross-entropy which provides a loss value within the logarithmic scale. In general, loss will describe to us how well our model reflects the training data. It compares the predicted output versus the target output.\n",
    "Accuracy is the ratio of correct predictions versus all predictions. \n",
    "\n",
    "Since our Positive class is 'Male' and our Negative class is 'Female', technically all True Positives are all correct predictions of 'Male' and all True Negatives are all correct predictions of 'Female'. Therefore 100% of TP are Male and 100% of TN are Female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:** Proportion of correct prediction out of total prediction of the training/testing data.\n",
    "- The higher the better\n",
    "<br>\n",
    "\n",
    "**Loss:** Measures the difference between the predicted and true output of the training/testing data. \n",
    "- The lower the better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
